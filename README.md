# Regdriver-SC
Regdriver-SC can be used to distinguish driver mutations from non-driver mutations, identify true driver events, and integrates mutation impact scoring with mutation burden analysis.

#1.Create the initial environment
conda create -n Regdriver-SC python=3.8
conda activate Regdriver-SC

# (optional if you would like to use flash attention)
# install triton from source
git clone https://github.com/openai/triton.git
cd triton/python
pip install cmake       # 构建依赖
pip install -e .        # 从源码安装 Triton
python3 -m pip install -r requirements.txt
conda install -c huggingface transformers
conda install -c bioconda pyfaidx
conda install pytorch torchvision torchaudio cpuonly -c pytorch

conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

#versions
  - python=3.8
  - samtools
  - pandas
  - bedtools
  - numpy
  - openjdk=8
  - tabix
  - htslib
  - pyfaidx
  - r-base=3.5.1
  - cudatoolkit=10.2
  - pytorch=1.7.1

#2. Extracting sequence features

  python extract_features.py --model_path zhihan1996/DNABERT-2-117M \
  --train_file /path/data/blood1.bed \
  --test_file  /path/data/blood2.bed \
  --output_dir /path/output \
  --train_output_name blood_mutation1.npy \
  --test_output_name  blood_mutation2.npy

#Dataset Description
The files blood1.bed and blood2.bed are example datasets provided with this repository.
In total, the repository includes 13 tissue-specific .bed files (e.g., blood, brain, liver, etc.), 
each containing the initial DNA sequence information used in our model.
If you wish to use your own data, simply replace these example .bed files with your own files following the same format.
Additionally, precomputed feature files — blood_mutation1.npy and blood_mutation2.npy — are provided as example outputs generated by running the script.

#3.Calculation of prediction probability difference
python predict_delta_prob.py \
  --model_path /path/model/blood_model.pth \
  --pre_meta  /path/data/mutation1/blood1.bed \
  --post_meta /path/data/mutation2/blood2.bed \
  --pre_feat  /path/output/blood_mutation1.npy \
  --post_feat /path/output/blood_mutation2.npy \
  --output    /path/output/blood_prob.bed 

#4.Make response tables
The response (y; dependent variable) table records the observed number of mutations, 
number of mutated samples and the length per genomic element. This table is required 
for both model (training) and  infer (test) sub-commands.

python prepare.py \
  /path/data/mutation_hg19/blood_non_coding_hg19.maf \
  /path/data/hg_19/blood_merged.bed \
  /path/data/callable.bed \
  /outpath/blood.tsv


#5.Construct a background mutation model

The background mutation rate (BMR) model is used to estimate the expected number of somatic mutations for each genomic element, given its features. 
python background.py \
  --X_path /path/data/merge_features/blood_all.bed \
  --y_path /path/data/response/blood.tsv \
  --out_dir /path/output/background_Binomial \
  --project_name blood 

#6. Mutation Impact Scoring Correction + Burden Test

python infer_mutation_burden_impact.py \
  --mutations_maf /path/data/mutation_hg19/blood_non_coding_hg19.maf \
  --regions_bed1   /path/data/hg_19/blood_merged.bed \
  --model_path   /path/output/background_Binomial.pkl \
  --X_path       /path/data/merge_features/blood_all.bed \
  --y_path       /path/data/response/blood.tsv \
  --regions_bed  /path/output/blood_prob.bed  \
  --out_dir      /path/output/Mutation_impact_score_burden/ \
  --project_name blood 





